#!/bin/bash

#==================================================
# サロン予約リマインド - 完全自動スクレイピングスクリプト
# 全問題対応版
#==================================================

set -euo pipefail  # エラー時即座に停止

# 絶対パス定義
SCRIPT_DIR="/Users/kanbararyousuke/salon-absence-system"
VENV_PATH="$SCRIPT_DIR/venv/bin/activate"
ENV_FILE="$SCRIPT_DIR/.env"
LOG_DIR="$SCRIPT_DIR/logs"
LOG_FILE="$LOG_DIR/scrape_$(date +%Y%m%d).log"

# ロックファイル（同時実行防止）
LOCK_FILE="/tmp/salon_scrape.lock"

# 設定
MAX_RETRIES=3
RETRY_INTERVAL=900  # 15分
VPS_HOST="ubuntu@153.120.1.43"

#--------------------------------------------------
# ログ関数
#--------------------------------------------------
log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1" | tee -a "$LOG_FILE"
}

#--------------------------------------------------
# エラー通知関数
#--------------------------------------------------
send_error_notification() {
    local error_msg="$1"
    local date_label="$2"
    
    log "エラー通知送信: $error_msg"
    
    cd "$SCRIPT_DIR"
    source "$VENV_PATH"
    
    python3 << PYEOF
import os
import requests
from dotenv import load_dotenv

load_dotenv("$ENV_FILE")

message = """⚠️ スクレイピングエラー

${date_label}の予約取得に失敗しました。
サロンボードをご確認ください。

エラー: ${error_msg}
時刻: $(date '+%Y/%m/%d %H:%M')"""

url = 'https://api.line.me/v2/bot/message/push'
headers = {
    'Content-Type': 'application/json',
    'Authorization': f'Bearer {os.getenv("LINE_CHANNEL_ACCESS_TOKEN")}'
}
data = {
    'to': os.getenv('TEST_LINE_USER_ID'),
    'messages': [{'type': 'text', 'text': message}]
}

try:
    response = requests.post(url, headers=headers, json=data, timeout=30)
    if response.status_code == 200:
        print("✅ エラー通知送信成功")
    else:
        print(f"❌ エラー通知送信失敗: {response.status_code}")
except Exception as e:
    print(f"❌ エラー通知送信失敗: {e}")
PYEOF
}

#--------------------------------------------------
# ロックファイルチェック（同時実行防止）
#--------------------------------------------------
if [ -f "$LOCK_FILE" ]; then
    # ロックファイルが1時間以上古い場合は削除
    if [ $(($(date +%s) - $(stat -f %m "$LOCK_FILE"))) -gt 3600 ]; then
        log "古いロックファイルを削除"
        rm -f "$LOCK_FILE"
    else
        log "❌ 既に実行中です。終了します。"
        exit 1
    fi
fi

# ロックファイル作成
touch "$LOCK_FILE"
trap "rm -f $LOCK_FILE" EXIT

#--------------------------------------------------
# メイン処理開始
#--------------------------------------------------
log "=========================================="
log "スクレイピング処理開始"
log "=========================================="

# ログディレクトリ作成
mkdir -p "$LOG_DIR"

# 仮想環境有効化
cd "$SCRIPT_DIR"
source "$VENV_PATH"

# 日付計算（BSD date対応）
THREE_DAYS=$(date -v+3d +%Y%m%d)
SEVEN_DAYS=$(date -v+7d +%Y%m%d)

log "対象日付: 3日後=$THREE_DAYS, 7日後=$SEVEN_DAYS"

#--------------------------------------------------
# スクレイピング＆アップロード関数
#--------------------------------------------------
scrape_and_upload() {
    local target_date=$1
    local days_label=$2
    local output_filename=$3
    
    log "------------------------------------------"
    log "[$days_label] 処理開始: $target_date"
    log "------------------------------------------"
    
    for attempt in $(seq 1 $MAX_RETRIES); do
        log "[$days_label] 試行 $attempt/$MAX_RETRIES"
        
        # スクレイピング実行
        cp scrape_with_phone_final.py temp_scrape_${days_label}.py
        
        # BSD sed対応（Macの場合 -i '' が必要）
        sed -i '' "17s/datetime.now().strftime('%Y%m%d')/'$target_date'/" temp_scrape_${days_label}.py
        
        if python3 temp_scrape_${days_label}.py >> "$LOG_FILE" 2>&1; then
            # 最新のJSONファイルを取得
            LATEST_JSON=$(ls -t scrape_result_with_phone_*.json 2>/dev/null | head -1)
            
            if [ -z "$LATEST_JSON" ]; then
                log "[$days_label] エラー: JSONファイルが見つかりません"
                rm -f temp_scrape_${days_label}.py
                continue
            fi
            
            # ファイルサイズチェック（200バイト以下なら失敗扱い）
            FILE_SIZE=$(stat -f%z "$LATEST_JSON")
            
            if [ "$FILE_SIZE" -gt 200 ]; then
                log "[$days_label] ✅ スクレイピング成功 (${FILE_SIZE}バイト)"
                
                # タイムスタンプ付きでリネーム（世代管理）
                TIMESTAMPED_FILE="${days_label}_$(date +%Y%m%d_%H%M%S).json"
                cp "$LATEST_JSON" "$TIMESTAMPED_FILE"
                
                # VPSに転送（SSH鍵認証）
                log "[$days_label] VPSに転送中..."
                
                if scp -o ConnectTimeout=30 "$LATEST_JSON" "${VPS_HOST}:~/${output_filename}" >> "$LOG_FILE" 2>&1; then
                    log "[$days_label] ✅ 転送成功"
                    
                    # クリーンアップ
                    rm -f temp_scrape_${days_label}.py
                    
                    return 0
                else
                    log "[$days_label] ❌ 転送失敗"
                fi
            else
                log "[$days_label] ❌ 空のデータ (${FILE_SIZE}バイト)"
            fi
        else
            log "[$days_label] ❌ スクレイピング失敗"
        fi
        
        # クリーンアップ
        rm -f temp_scrape_${days_label}.py
        
        # リトライ前の待機
        if [ $attempt -lt $MAX_RETRIES ]; then
            log "[$days_label] $(($RETRY_INTERVAL / 60))分後にリトライ..."
            sleep $RETRY_INTERVAL
        fi
    done
    
    # 全試行失敗
    log "[$days_label] ❌ 全試行失敗"
    send_error_notification "3回のリトライすべて失敗" "$days_label ($target_date)"
    
    return 1
}

#--------------------------------------------------
# 実行
#--------------------------------------------------
# 3日後
scrape_and_upload "$THREE_DAYS" "3日後" "scrape_result_3days.json"
THREE_DAYS_RESULT=$?

# 5分待機（Bot判定回避）
if [ $THREE_DAYS_RESULT -eq 0 ]; then
    log "Bot判定回避のため5分待機..."
    sleep 300
fi

# 7日後
scrape_and_upload "$SEVEN_DAYS" "7日後" "scrape_result_7days.json"
SEVEN_DAYS_RESULT=$?

#--------------------------------------------------
# 完了
#--------------------------------------------------
log "=========================================="
if [ $THREE_DAYS_RESULT -eq 0 ] && [ $SEVEN_DAYS_RESULT -eq 0 ]; then
    log "✅ 全処理完了"
elif [ $THREE_DAYS_RESULT -eq 0 ] || [ $SEVEN_DAYS_RESULT -eq 0 ]; then
    log "⚠️ 部分的に完了"
else
    log "❌ 全処理失敗"
fi
log "=========================================="

exit 0
